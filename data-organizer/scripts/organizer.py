#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ•´ç†ä¸»ç¨‹åº
æ‰«ææ–‡ä»¶å¤¹ï¼Œæå–æ–‡ä»¶å†…å®¹ï¼Œæ•´ç†æˆç»Ÿä¸€æ ¼å¼è¾“å‡º
è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„ Python ç‰ˆæœ¬ä»¥æ”¯æŒ PaddleOCR
"""

import os
import sys
import subprocess
import argparse
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Tuple

# è‡ªåŠ¨æ£€æµ‹å“ªä¸ª Python ç‰ˆæœ¬æœ‰ PaddleOCR
def _get_python_with_paddleocr():
    """æ£€æµ‹å“ªä¸ª Python ç‰ˆæœ¬æœ‰ PaddleOCRï¼Œè¿”å›ç‰ˆæœ¬å‘½ä»¤"""
    for version in ['python3.10', 'python3.11', 'python3']:
        try:
            result = subprocess.run(
                [version, '-c', 'from paddleocr import PaddleOCR'],
                capture_output=True, timeout=10
            )
            if result.returncode == 0:
                return version
        except:
            continue
    return None  # éƒ½æ²¡æœ‰

_PYTHON_FOR_PDF = None  # ç¼“å­˜ç»“æœ

def get_python_for_pdf():
    """è·å–å¯ç”¨äº OCR çš„ Python ç‰ˆæœ¬"""
    global _PYTHON_FOR_PDF
    if _PYTHON_FOR_PDF is None:
        _PYTHON_FOR_PDF = _get_python_with_paddleocr()
    return _PYTHON_FOR_PDF

from file_handler import process_file, get_file_type

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹åˆ—è¡¨
SUPPORTED_TYPES = [
    '.pdf', '.xlsx', '.xls', '.docx', '.csv', '.json',
    '.txt', '.md', '.log', '.png', '.jpg', '.jpeg', '.gif', '.bmp'
]

# RAG ç³»ç»Ÿå¯ä»¥ç›´æ¥å¤„ç†çš„æ–‡ä»¶ç±»å‹ï¼ˆæ— éœ€è½¬æ¢ï¼‰
RAG_NATIVE_TYPES = {'.md', '.txt', '.json', '.csv'}


def scan_directory(path: str, recursive: bool = False) -> Tuple[List[str], List[str]]:
    """
    æ‰«æç›®å½•è·å–æ–‡ä»¶åˆ—è¡¨

    Args:
        path: ç›®å½•è·¯å¾„
        recursive: æ˜¯å¦é€’å½’æ‰«æå­ç›®å½•

    Returns:
        (éœ€è¦è½¬æ¢çš„æ–‡ä»¶åˆ—è¡¨, RAG åŸç”Ÿæ–‡ä»¶åˆ—è¡¨)
    """
    dir_path = Path(path)

    if not dir_path.exists():
        raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {path}")

    if not dir_path.is_dir():
        raise NotADirectoryError(f"ä¸æ˜¯ç›®å½•: {path}")

    if recursive:
        files = [str(f) for f in dir_path.rglob('*') if f.is_file()]
    else:
        files = [str(f) for f in dir_path.glob('*') if f.is_file()]

    # è¿‡æ»¤æ”¯æŒçš„æ–‡ä»¶ç±»å‹
    supported_files = []
    skipped_by_rag = []
    for f in files:
        ext = Path(f).suffix.lower()
        if ext in SUPPORTED_TYPES:
            if ext in RAG_NATIVE_TYPES:
                skipped_by_rag.append(f)
            else:
                supported_files.append(f)

    if skipped_by_rag:
        print(f"[DATA-ORGANIZER] â­ï¸ å‘ç° {len(skipped_by_rag)} ä¸ª RAG åŸç”Ÿæ–‡ä»¶")

    return sorted(supported_files), sorted(skipped_by_rag)


def get_skipped_files(path: str, recursive: bool = False, exclude: List[str] = None) -> List[str]:
    """
    è·å–è¢«è·³è¿‡çš„ RAG åŸç”Ÿæ–‡ä»¶åˆ—è¡¨

    Args:
        path: ç›®å½•è·¯å¾„
        recursive: æ˜¯å¦é€’å½’æ‰«æå­ç›®å½•
        exclude: æ’é™¤çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆè¾“å‡ºæ–‡ä»¶ç­‰ï¼‰

    Returns:
        RAG åŸç”Ÿæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    dir_path = Path(path)

    if not dir_path.exists():
        return []

    if recursive:
        files = [str(f) for f in dir_path.rglob('*') if f.is_file()]
    else:
        files = [str(f) for f in dir_path.glob('*') if f.is_file()]

    exclude_set = set(exclude or [])
    return [f for f in files if Path(f).suffix.lower() in RAG_NATIVE_TYPES and f not in exclude_set]


def generate_summary(files: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ç”Ÿæˆæ•´ç†ç»“æœæ‘˜è¦

    Args:
        files: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨

    Returns:
        åŒ…å«æ‘˜è¦ä¿¡æ¯çš„å­—å…¸
    """
    type_counts = {}
    total_size = 0

    for f in files:
        file_type = f['type']
        type_counts[file_type] = type_counts.get(file_type, 0) + 1
        total_size += f['metadata'].get('size', 0)

    return {
        'total_files': len(files),
        'by_type': type_counts,
        'total_size_bytes': total_size,
    }


def format_to_json(files: List[Dict[str, Any]], summary: Dict[str, Any]) -> str:
    """
    æ ¼å¼åŒ–ä¸º JSON è¾“å‡º

    Args:
        files: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        summary: æ‘˜è¦ä¿¡æ¯

    Returns:
        JSON æ ¼å¼å­—ç¬¦ä¸²
    """
    output = {
        'generated_at': datetime.now().isoformat(),
        'summary': summary,
        'files': files,
    }
    return json.dumps(output, ensure_ascii=False, indent=2)


def format_to_markdown(files: List[Dict[str, Any]], summary: Dict[str, Any]) -> str:
    """
    æ ¼å¼åŒ–ä¸º Markdown è¾“å‡º

    Args:
        files: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        summary: æ‘˜è¦ä¿¡æ¯

    Returns:
        Markdown æ ¼å¼å­—ç¬¦ä¸²
    """
    lines = []

    lines.append("# æ–‡ä»¶æ•´ç†æŠ¥å‘Š\n")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    lines.append("## ç»Ÿè®¡æ‘˜è¦")
    lines.append(f"- æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
    lines.append(f"- æ€»å¤§å°: {summary['total_size_bytes']:,} bytes")

    lines.append("\n### æŒ‰ç±»å‹ç»Ÿè®¡")
    for file_type, count in sorted(summary['by_type'].items()):
        lines.append(f"- {file_type}: {count}")

    lines.append("\n---\n")
    lines.append("## æ–‡ä»¶åˆ—è¡¨\n")

    for i, f in enumerate(files, 1):
        lines.append(f"### {i}. {f['name']}")
        lines.append(f"- **è·¯å¾„**: {f['path']}")
        lines.append(f"- **ç±»å‹**: {f['type']}")
        lines.append(f"- **å¤§å°**: {f['metadata'].get('size', 'N/A')} bytes")

        if f['content']:
            lines.append("\n**å†…å®¹é¢„è§ˆ**:")
            content_preview = f['content'][:500]
            if len(f['content']) > 500:
                content_preview += "..."
            lines.append(f"```\n{content_preview}\n```")

        lines.append("\n---\n")

    return '\n'.join(lines)


def interactive_mode() -> Dict[str, Any]:
    """
    äº¤äº’å¼æ¨¡å¼ï¼Œå¼•å¯¼ç”¨æˆ·å®Œæˆæ•´ç†æµç¨‹

    Returns:
        åŒ…å«ç”¨æˆ·é€‰æ‹©çš„å­—å…¸
    """
    print("\n=== Data Organizer äº¤äº’å¼æ¨¡å¼ ===\n")

    # 1. è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
    while True:
        input_path = input("è¯·è¾“å…¥è¦æ•´ç†çš„æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
        if os.path.exists(input_path) and os.path.isdir(input_path):
            break
        print("è·¯å¾„æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

    # 2. é€‰æ‹©æ˜¯å¦é€’å½’
    while True:
        recursive_input = input("æ˜¯å¦æ‰«æå­ç›®å½•? (y/n): ").strip().lower()
        if recursive_input in ['y', 'yes']:
            recursive = True
            break
        elif recursive_input in ['n', 'no']:
            recursive = False
            break

    # 3. é€‰æ‹©è¾“å‡ºæ ¼å¼
    print("\nè¯·é€‰æ‹©è¾“å‡ºæ ¼å¼:")
    print("  1. JSON")
    print("  2. Markdown")
    while True:
        format_choice = input("è¯·é€‰æ‹© (1/2): ").strip()
        if format_choice == '1':
            output_format = 'json'
            break
        elif format_choice == '2':
            output_format = 'markdown'
            break

    # 4. é€‰æ‹©è¾“å‡ºæ–¹å¼
    print("\nè¯·é€‰æ‹©è¾“å‡ºæ–¹å¼:")
    print("  1. ä¿å­˜åˆ°æ–‡ä»¶")
    print("  2. ä»…æ˜¾ç¤ºå†…å®¹")
    while True:
        output_choice = input("è¯·é€‰æ‹© (1/2): ").strip()
        if output_choice in ['1', '2']:
            save_to_file = (output_choice == '1')
            break

    output_path = None
    if save_to_file:
        default_name = f"organized_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        output_path = input(f"è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤ '{default_name}'): ").strip()
        if not output_path:
            output_path = default_name

    return {
        'input': input_path,
        'recursive': recursive,
        'format': output_format,
        'output': output_path,
        'save_to_file': save_to_file,
    }


def organize_files(options: Dict[str, Any], progress_callback=None) -> Dict[str, Any]:
    """
    æ‰§è¡Œæ–‡ä»¶æ•´ç†

    Args:
        options: åŒ…å«æ•´ç†é€‰é¡¹çš„å­—å…¸
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (current, total, filename)

    Returns:
        åŒ…å«ç»“æœå’Œæ‘˜è¦çš„å­—å…¸
    """
    input_path = options['input']
    recursive = options['recursive']
    output_format = options['format']
    output_path = options.get('output')
    save_to_file = options.get('save_to_file', True)

    # è¾“å‡ºä¿¡æ¯
    print(f"[DATA-ORGANIZER] å¼€å§‹æ‰«æ: {input_path}")
    if recursive:
        print(f"[DATA-ORGANIZER] æ¨¡å¼: é€’å½’æ‰«æ")

    # æ‰«ææ–‡ä»¶
    files, skipped_by_rag = scan_directory(input_path, recursive)
    total_files = len(files)

    # å¤„ç† RAG åŸç”Ÿæ–‡ä»¶ï¼šç§»åŠ¨åˆ° jxh_data ç›®å½•
    moved_to_rag = []
    if skipped_by_rag and output_path:
        rag_dir = Path(output_path)
        rag_dir.mkdir(parents=True, exist_ok=True)
        for f in skipped_by_rag:
            try:
                src = Path(f)
                dst = rag_dir / src.name
                import shutil
                shutil.move(str(src), str(dst))
                moved_to_rag.append(str(dst))
                print(f"[DATA-ORGANIZER] â†’ RAG: {src.name}")
            except Exception as e:
                print(f"[DATA-ORGANIZER] ç§»åŠ¨å¤±è´¥ {f}: {e}")

    if moved_to_rag:
        print(f"[DATA-ORGANIZER] å·²ç§»åŠ¨ {len(moved_to_rag)} ä¸ªæ–‡ä»¶åˆ° RAG ç›®å½•")

    if total_files == 0 and not moved_to_rag:
        result = {"status": "no_files", "message": "æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶"}
        print(f"[DATA-ORGANIZER] æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶")
        return result

    print(f"[DATA-ORGANIZER] å‘ç° {total_files} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")

    # å¤„ç†æ–‡ä»¶
    file_infos = []
    failed_files = []
    for i, f in enumerate(files, 1):
        filename = Path(f).name
        print(f"[DATA-ORGANIZER] è¿›åº¦: {i}/{total_files} - {filename}")
        if progress_callback:
            progress_callback(i, total_files, filename)

        try:
            file_info = process_file(f)
            file_infos.append(file_info)
        except Exception as e:
            print(f"[DATA-ORGANIZER] å¤„ç†å¤±è´¥: {filename} - {e}")
            failed_files.append({
                "name": filename,
                "path": f,
                "error": str(e)
            })

    print(f"[DATA-ORGANIZER] æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆç»“æœ...")

    # ç”Ÿæˆæ‘˜è¦
    summary = generate_summary(file_infos)

    # æ ¼å¼åŒ–è¾“å‡º
    if output_format == 'json':
        output_content = format_to_json(file_infos, summary)
    else:
        output_content = format_to_markdown(file_infos, summary)

    # æ˜¾ç¤ºæ‘˜è¦
    print(f"[DATA-ORGANIZER] å®Œæˆ! æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
    for file_type, count in sorted(summary['by_type'].items()):
        print(f"[DATA-ORGANIZER]   - {file_type}: {count}")

    output_full_path = None
    output_files = []  # ä¿å­˜è¾“å‡ºæ–‡ä»¶åˆ—è¡¨

    if save_to_file and output_path:
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨

        # æ€»æ˜¯è¾“å‡º MD + JSON
        if len(file_infos) == 1:
            # å•ä¸ªæ–‡ä»¶ï¼šä¿ç•™åŸæ–‡ä»¶å
            original_name = Path(file_infos[0]['path']).stem  # å»æ‰æ‰©å±•å
        else:
            # å¤šä¸ªæ–‡ä»¶ï¼šä½¿ç”¨ organized
            original_name = "organized"

        # ä¿å­˜ Markdown
        md_file = output_path / f"{original_name}.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(output_content)

        # ä¿å­˜ JSONï¼ˆåŒ…å« OCR ç»“æ„åŒ–æ•°æ®ï¼‰
        json_output = {
            'generated_at': datetime.now().isoformat(),
            'summary': summary,
            'files': file_infos,
        }
        json_file = output_path / f"{original_name}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_output, f, ensure_ascii=False, indent=2)

        output_full_path = str(md_file)
        for fi in file_infos:
            output_files.append({
                "original": fi['name'],
                "output": f"{original_name}.md",
                "json_output": f"{original_name}.json"
            })
        print(f"[DATA-ORGANIZER] ç»“æœå·²ä¿å­˜: {md_file} + {json_file}")

    # ç§»åŠ¨åˆ° processed ç›®å½•ï¼Œä¿ç•™ 7 å¤©åç”± cron æ¸…ç†
    cleaned_files = []
    processed_dir = Path(input_path) / ".processed"
    processed_dir.mkdir(exist_ok=True)

    for f in files:
        try:
            src = Path(f)
            dst = processed_dir / src.name
            import shutil
            shutil.move(str(src), str(dst))
            cleaned_files.append(src.name)
        except Exception as e:
            print(f"[DATA-ORGANIZER] ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {f} - {e}")

    if cleaned_files:
        print(f"[DATA-ORGANIZER] å·²ç§»åŠ¨ {len(cleaned_files)} ä¸ªæ–‡ä»¶åˆ° .processedï¼ˆä¿ç•™7å¤©ï¼‰")

    # è¿”å›ç»“æœä¾› Agent ä½¿ç”¨
    return {
        "status": "success",
        "total_files": summary['total_files'],
        "by_type": summary['by_type'],
        "output_files": output_files,
        "output_file": output_full_path,
        "cleaned_files": cleaned_files,
        "failed": failed_files,
        "moved_to_rag": moved_to_rag,
        "summary": {
            **summary,
            "files": file_infos
        }
    }


def format_to_telegram_summary(result: Dict, processed_count: int = 0) -> str:
    """
    æ ¼å¼åŒ–ä¸º Telegram ç®€æ´çŠ¶æ€æŠ¥å‘Š

    Args:
        result: organize_files è¿”å›çš„ç»“æœ
        processed_count: å·²å¤„ç†çš„æ–‡ä»¶æ•°ï¼ˆç”¨äºè¿›åº¦æ˜¾ç¤ºï¼‰

    Returns:
        Telegram æ ¼å¼å­—ç¬¦ä¸²
    """
    if result.get('status') == 'no_files':
        return "ğŸ“­ **æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶**"

    lines = []

    # å¤„ç†è¿›åº¦
    total = result.get('total_files', 0)
    if total > 0:
        lines.append(f"ğŸ”„ **å¤„ç†ä¸­**: {processed_count}/{total}")
        lines.append("")  # ç©ºè¡Œ

    # å¤±è´¥çš„æ–‡ä»¶
    failed = result.get('failed', [])
    if failed:
        lines.append("âŒ **å¤±è´¥**:")
        for f in failed:
            lines.append(f"   â€¢ {f['name']}: {f.get('error', 'æœªçŸ¥é”™è¯¯')}")
        lines.append("")

    # æˆåŠŸçš„æ–‡ä»¶
    success = result.get('output_files', [])
    if success:
        lines.append("âœ… **æˆåŠŸ**:")
        for f in success:
            name = f.get('original', f.get('output', f.get('name', 'Unknown')))
            lines.append(f"   â€¢ {name}")
        lines.append("")

    # ç§»åŠ¨åˆ° RAG ç›®å½•çš„æ–‡ä»¶
    moved = result.get('moved_to_rag', [])
    if moved:
        lines.append("â­ï¸ **å·²ç§»è‡³ RAG ç›®å½•**:")
        for f in moved:
            lines.append(f"   â€¢ {Path(f).name}")
        lines.append("")

    # æ¸…ç†çš„æ–‡ä»¶
    cleaned = result.get('cleaned_files', [])
    if cleaned:
        lines.append(f"ğŸ—‘ï¸ **å·²æ¸…ç†**: {len(cleaned)} ä¸ªåŸå§‹æ–‡ä»¶")

    return '\n'.join(lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='è‡ªåŠ¨æ•´ç†æ–‡ä»¶å¤¹ä¸­çš„å„ç±»æ–‡ä»¶ï¼Œæå–å†…å®¹å¹¶ç»Ÿä¸€è¾“å‡º',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        '-i', '--input',
        help='å¾…æ‰«æçš„æ–‡ä»¶å¤¹è·¯å¾„'
    )

    parser.add_argument(
        '-o', '--output',
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰'
    )

    parser.add_argument(
        '-f', '--format',
        choices=['json', 'markdown'],
        default='json',
        help='è¾“å‡ºæ ¼å¼: json æˆ– markdown (é»˜è®¤: json)'
    )

    parser.add_argument(
        '-r', '--recursive',
        action='store_true',
        help='é€’å½’æ‰«æå­ç›®å½•'
    )

    parser.add_argument(
        '--interactive',
        action='store_true',
        help='ä½¿ç”¨äº¤äº’å¼æ¨¡å¼'
    )

    parser.add_argument(
        '--json',
        action='store_true',
        help='ä»¥ JSON æ ¼å¼è¾“å‡ºç»“æœæ‘˜è¦ï¼ˆä¾› Agent ä½¿ç”¨ï¼‰'
    )

    parser.add_argument(
        '--telegram',
        action='store_true',
        help='ä»¥ Telegram æ¶ˆæ¯æ ¼å¼è¾“å‡ºï¼ˆç®€æ´æ‘˜è¦ï¼Œä¸å«å†…å®¹é¢„è§ˆï¼‰'
    )

    args = parser.parse_args()

    if args.interactive or not args.input:
        # äº¤äº’å¼æ¨¡å¼
        options = interactive_mode()
    else:
        # å‘½ä»¤è¡Œæ¨¡å¼
        options = {
            'input': args.input,
            'output': args.output,
            'format': args.format,
            'recursive': args.recursive,
            'save_to_file': bool(args.output),
        }

    try:
        result = organize_files(options)

        # å¦‚æœæŒ‡å®šäº† --jsonï¼Œè¾“å‡ºæœºå™¨å¯è¯»çš„ç»“æœ
        if args.json and result:
            print(f"[RESULT_START]{json.dumps(result, ensure_ascii=False)}[RESULT_END]")

        # å¦‚æœæŒ‡å®šäº† --telegramï¼Œè¾“å‡ºç®€æ´æ‘˜è¦
        if args.telegram and result.get('status') == 'success':
            tg_summary = format_to_telegram_summary(result)
            print(tg_summary)

    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·å–æ¶ˆæ“ä½œã€‚")
        sys.exit(0)
    except Exception as e:
        print(f"\né”™è¯¯: {str(e)}")
        sys.exit(1)


if __name__ == '__main__':
    main()
